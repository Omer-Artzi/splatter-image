# -*- coding: utf-8 -*-
"""train_network.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_lFPNw-yqmOt1XVnaON4qzLXkT9iGT_D
"""

import glob
import hydra
import os
import wandb

import numpy as np
import torch
from torch.utils.data import DataLoader
from lightning.fabric import Fabric
from ema_pytorch import EMA
from omegaconf import DictConfig, OmegaConf

from utils.general_utils import safe_state
from utils.loss_utils import combined_l1_loss, combined_l2_loss
import lpips as lpips_lib

from eval import evaluate_dataset
from gaussian_renderer import render_predicted
from scene.gaussian_predictor import GaussianSplatPredictor
from datasets.dataset_factory import get_dataset
import matplotlib.pyplot as plt

# Function to visualize and save layers
def visualize_and_save_layer(layer_image, layer_name, step, save_dir):
    layer_image = layer_image.clamp(0, 1).detach().cpu().numpy().transpose(1, 2, 0)

    # Plot the image
    plt.imshow(layer_image)
    plt.title(f"{layer_name} at Step {step}")
    plt.axis('off')

    # Save the plot
    save_path = os.path.join(save_dir, f"{layer_name}_step_{step}.png")
    plt.savefig(save_path)
    plt.close()

@hydra.main(version_base=None, config_path='configs', config_name="default_config")
def main(cfg: DictConfig):

    torch.set_float32_matmul_precision('high')
    fabric = Fabric(accelerator="cuda", devices=cfg.general.num_devices, strategy="ddp",
                    precision="16-mixed" if cfg.general.mixed_precision else '32-true')
    fabric.launch()

    if fabric.is_global_zero:
        vis_dir = os.getcwd()

        dict_cfg = OmegaConf.to_container(cfg, resolve=True, throw_on_missing=True)

        if os.path.isdir(os.path.join(vis_dir, "wandb")):
            run_name_path = glob.glob(os.path.join(vis_dir, "wandb", "latest-run", "run-*"))[0]
            run_id = os.path.basename(run_name_path).split("run-")[1].split(".wandb")[0]
            wandb_run = wandb.init(project=cfg.wandb.project, resume=True, id=run_id, config=dict_cfg)
        else:
            wandb_run = wandb.init(project=cfg.wandb.project, reinit=True, config=dict_cfg)

    first_iter = 0
    device = safe_state(cfg)

    gaussian_predictor = GaussianSplatPredictor(cfg).to(memory_format=torch.channels_last)

    optimizer = torch.optim.Adam([{'params': gaussian_predictor.parameters(), 'lr': cfg.opt.base_lr}],
                                 lr=0.0, eps=1e-15, betas=cfg.opt.betas)

    if fabric.is_global_zero:
        if os.path.isfile(os.path.join(vis_dir, "model_latest.pth")):
            checkpoint = torch.load(os.path.join(vis_dir, "model_latest.pth"), map_location=device)
            gaussian_predictor.load_state_dict(checkpoint["model_state_dict"], strict=False)
            first_iter = checkpoint["iteration"]
            best_PSNR = checkpoint["best_PSNR"]
        else:
            best_PSNR = 0.0

    if cfg.opt.ema.use and fabric.is_global_zero:
        ema = EMA(gaussian_predictor, beta=cfg.opt.ema.beta,
                  update_every=cfg.opt.ema.update_every,
                  update_after_step=cfg.opt.ema.update_after_step)
        ema = fabric.to_device(ema)

    if cfg.opt.loss == "l2":
        loss_fn = combined_l2_loss
    elif cfg.opt.loss == "l1":
        loss_fn = combined_l1_loss

    if cfg.opt.lambda_lpips != 0:
        lpips_fn = fabric.to_device(lpips_lib.LPIPS(net='vgg'))
    lambda_lpips = cfg.opt.lambda_lpips
    lambda_l12 = 1.0 - lambda_lpips

    bg_color = [1, 1, 1] if cfg.data.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32)
    background = fabric.to_device(background)

    dataset = get_dataset(cfg, "train")
    dataloader = DataLoader(dataset, batch_size=cfg.opt.batch_size, shuffle=True,
                            num_workers=12 if cfg.data.category in ["nmr", "objaverse"] else 0)

    val_dataset = get_dataset(cfg, "val")
    val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)

    gaussian_predictor, optimizer = fabric.setup(gaussian_predictor, optimizer)
    dataloader = fabric.setup_dataloaders(dataloader)

    gaussian_predictor.train()

    first_iter += 1
    iteration = first_iter

    # Directory to save the plots
    save_dir = os.path.join(vis_dir, "plots")
    os.makedirs(save_dir, exist_ok=True)

    for num_epoch in range((cfg.opt.iterations + 1 - first_iter) // len(dataloader) + 1):
        dataloader.sampler.set_epoch(num_epoch)

        for data in dataloader:
            iteration += 1

            rot_transform_quats = data["source_cv2wT_quat"][:, :cfg.data.input_images]
            focals_pixels_pred = data.get("focals_pixels")[:, :cfg.data.input_images, ...] if cfg.data.category in ["hydrants", "teddybears"] else None
            input_images = data["gt_images"][:, :cfg.data.input_images, ...]

            # Get predictions for both front and back layers
            pred_front = gaussian_predictor(input_images, data["view_to_world_transforms"][:, :cfg.data.input_images, ...], rot_transform_quats, focals_pixels_pred)
            pred_back = gaussian_predictor(input_images, data["view_to_world_transforms"][:, :cfg.data.input_images, ...], rot_transform_quats, focals_pixels_pred)

            # Visualize and save both layers
            visualize_and_save_layer(pred_front, "Front Layer", iteration, save_dir)
            visualize_and_save_layer(pred_back, "Back Layer", iteration, save_dir)

            # Compute loss using combined loss functions
            total_loss = loss_fn(pred_front, data["gt_images"], pred_back, data["gt_images"])

            total_loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            if cfg.opt.ema.use and fabric.is_global_zero:
                ema.update()

            gaussian_predictor.eval()

            # Log training loss
            if iteration % cfg.logging.loss_log == 0 and fabric.is_global_zero:
                wandb.log({"training_loss": total_loss.item()}, step=iteration)

    wandb_run.finish()


if __name__ == "__main__":
    main()